{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('usr')"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## classificação com sklearn\n",
    "mostrar um animal e falar se é porco ou cachorro, 0 ou 1, binária\n",
    "aprendizado supervisionado com estimadores\n",
    "\n",
    "características:\n",
    "\n",
    "pelo longo ou curto\n",
    "\n",
    "perna curta ou não\n",
    "\n",
    "late? (au au)\n",
    "\n",
    "\n",
    "3 features pra classificar"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "\"\"\"\n",
    "Exemplo de tabela\n",
    "Animal\tPelo Longo?\tPerna curta?\tAu Au?\t0 cão or 1 porco?\n",
    "pig A\t1\t1\t0\t1\n",
    "pig B\t0\t1\t1\t1\n",
    "pig C\t0\t1\t0\t1\n",
    "dog A\t0\t1\t1\t0\n",
    "dog B\t1\t1\t1\t0\n",
    "dog C\t0\t0\t1\t0\n",
    "\"\"\""
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 45,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\\nExemplo de tabela\\nAnimal\\tPelo Longo?\\tPerna curta?\\tAu Au?\\t0 cão or 1 porco?\\npig A\\t1\\t1\\t0\\t1\\npig B\\t0\\t1\\t1\\t1\\npig C\\t0\\t1\\t0\\t1\\ndog A\\t0\\t1\\t1\\t0\\ndog B\\t1\\t1\\t1\\t0\\ndog C\\t0\\t0\\t1\\t0\\n'"
      ]
     },
     "metadata": {},
     "execution_count": 45
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "pig1 = [0,1,0]\n",
    "pig2 = [0,1,1]\n",
    "pig3 = [1,1,0]\n",
    "\n",
    "dog1 = [0,1,0]\n",
    "dog2 = [1,0,1]\n",
    "dog3 = [1,1,1]\n",
    "\n",
    "#f(x)=y, treinamento\n",
    "treino_x = [pig1,pig2,pig3,dog1,dog2,dog3]\n",
    "#ja que sabemos as classes, temos essas classificações\n",
    "# 1= porco, 0 = cachorro\n",
    "treino_y=[1,1,1,0,0,0] #labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LinearSVC()"
      ]
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "source": [
    "#import sklearn.vsm\n",
    "from sklearn.svm import LinearSVC\n",
    "# se não conseguir importar https://stackoverflow.com/questions/46113732/modulenotfounderror-no-module-named-sklearn/58029356#58029356\n",
    "# $ sudo apt install python3-sklearn \n",
    "model = LinearSVC()\n",
    "model.fit(dados,classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "source": [
    "animal_misterioso = [1,1,1]\n",
    "model.predict([animal_misterioso])"
   ]
  },
  {
   "source": [
    "## predizeu 0, que é um cachorro"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "misterio1=[1,1,1]\n",
    "misterio2=[1,1,0]\n",
    "misterio3=[0,1,1]\n",
    "\n",
    "teste_x = [misterio1,misterio2,misterio3]\n",
    "teste_y = [0,1,1]\n"
   ]
  },
  {
   "source": [
    "acha que é cachorro porco porco"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0 1 1]\n"
     ]
    }
   ],
   "source": [
    "previsoes = model.predict(teste_x)\n",
    "print(previsoes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([ True,  True,  True])"
      ]
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "source": [
    "#comparação entre previsto e real\n",
    "previsoes == testes_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Taxa de acerto: 100.0 %\n"
     ]
    }
   ],
   "source": [
    "num_corretos = (previsoes == testes_classes).sum()\n",
    "total =  len(teste)\n",
    "taxa_acerto = num_corretos/total\n",
    "print(\"Taxa de acerto:\",taxa_acerto*100,\"%\")\n"
   ]
  },
  {
   "source": [
    "### jeito mais fácil = acurácia"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Taxa de acerto:  100.0 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "acuracia = accuracy_score(testes_classes,previsoes)\n",
    "print(\"Taxa de acerto: \",acuracia*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}